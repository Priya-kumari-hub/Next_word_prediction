{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ujmDu79WSAzr"
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers datasets accelerate torch\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.is_available()\n"
      ],
      "metadata": {
        "id": "k5K8mKuSULPb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"wikitext\", \"wikitext-2-raw-v1\")\n",
        "\n",
        "dataset\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "9fK-RjscifHp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
        "import torch\n",
        "\n"
      ],
      "metadata": {
        "id": "r_B7BvwSl3sY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = GPT2Tokenizer.from_pretrained(\"distilgpt2\")\n",
        "tokenizer.pad_token = tokenizer.eos_token\n"
      ],
      "metadata": {
        "id": "V-7cjwZ_objW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = GPT2LMHeadModel.from_pretrained(\"distilgpt2\")\n",
        "model.resize_token_embeddings(len(tokenizer))\n"
      ],
      "metadata": {
        "id": "Ey2iq55joc4a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model.to(device)\n"
      ],
      "metadata": {
        "id": "cPSIjasdog-x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def tokenize_function(example):\n",
        "    return tokenizer(\n",
        "        example[\"text\"],\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",\n",
        "        max_length=128\n",
        "    )\n"
      ],
      "metadata": {
        "id": "X2TrMxUwiR_6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenized_dataset = dataset.map(\n",
        "    tokenize_function,\n",
        "    batched=True,\n",
        "    remove_columns=[\"text\"]\n",
        ")"
      ],
      "metadata": {
        "id": "DLWOLE02jxze"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_dataset = tokenized_dataset.map(\n",
        "    lambda x: {\"labels\": x[\"input_ids\"]},\n",
        "    batched=True\n",
        ")\n"
      ],
      "metadata": {
        "id": "lbh_skAyp_x9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer, TrainingArguments\n"
      ],
      "metadata": {
        "id": "DWpCmiVRqMr0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    overwrite_output_dir=True,\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=4,\n",
        "    logging_steps=100,\n",
        "    save_strategy=\"epoch\",\n",
        "    fp16=True,\n",
        "    report_to=\"none\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "Cs9b3Hk0qPCk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset[\"train\"]\n",
        ")\n"
      ],
      "metadata": {
        "id": "9f3phEArqpqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "BeiMftbAqrRO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "-mbIrUxLy_CC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SAVE_PATH = \"/content/drive/MyDrive/llm_next_word_project\"\n",
        "\n",
        "model.save_pretrained(SAVE_PATH)\n",
        "tokenizer.save_pretrained(SAVE_PATH)\n"
      ],
      "metadata": {
        "id": "inAHE0qaziYj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
        "import torch\n",
        "\n",
        "SAVE_PATH = \"/content/drive/MyDrive/llm_next_word_project\"\n",
        "\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(SAVE_PATH)\n",
        "model = GPT2LMHeadModel.from_pretrained(SAVE_PATH)\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model.to(device)\n",
        "model.eval()\n"
      ],
      "metadata": {
        "id": "cWhHkTJm26Y2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FZxp8Edw3tgR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_words_llm(prompt, max_new_tokens=50):\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=max_new_tokens,\n",
        "            do_sample=True,\n",
        "            top_k=50,\n",
        "            top_p=0.95,\n",
        "            temperature=0.8\n",
        "        )\n",
        "\n",
        "    return tokenizer.decode(output[0], skip_special_tokens=True)\n"
      ],
      "metadata": {
        "id": "7AEghih83PXQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(predict_next_words_llm(\"India is\"))\n"
      ],
      "metadata": {
        "id": "ZmvOv7Jp3hg0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(predict_next_words_llm(\"Technology will\"))\n"
      ],
      "metadata": {
        "id": "r3SU_Cgs35ES"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}