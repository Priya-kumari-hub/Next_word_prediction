{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17446,"status":"ok","timestamp":1740705464701,"user":{"displayName":"Priya Pandey","userId":"09641204841115482474"},"user_tz":-330},"id":"XNu5_YsyXxdB","outputId":"0ac9d873-c3e4-4ef9-c235-1d090eadc75b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"3saeE8Fry2vV","executionInfo":{"status":"ok","timestamp":1740750830985,"user_tz":-330,"elapsed":11,"user":{"displayName":"Priya Pandey","userId":"09641204841115482474"}}},"outputs":[],"source":["import os\n","import re\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n","from tensorflow.keras.callbacks import EarlyStopping\n","from tensorflow.keras.models import load_model"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"Mt-KpX6g4Nro","executionInfo":{"status":"ok","timestamp":1740750815045,"user_tz":-330,"elapsed":21,"user":{"displayName":"Priya Pandey","userId":"09641204841115482474"}}},"outputs":[],"source":["\n","# Function to read and split file into sentences\n","def file_to_sentence_list(file_path):\n","    with open(file_path, 'r', encoding='utf-8') as file:\n","        text = file.read()\n","\n","    # Splitting the text into sentences\n","    sentences = [sentence.strip() for sentence in re.split(\n","        r'(?<=[.!?])\\s+', text) if sentence.strip()]\n","\n","    return sentences"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":355,"status":"ok","timestamp":1740750815410,"user":{"displayName":"Priya Pandey","userId":"09641204841115482474"},"user_tz":-330},"id":"L2sMEUk34etM"},"outputs":[],"source":["file_path= '/content/drive/MyDrive/pizza.txt'\n","# Load text data\n","text_data = file_to_sentence_list(file_path)\n"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1740750838839,"user":{"displayName":"Priya Pandey","userId":"09641204841115482474"},"user_tz":-330},"id":"xUCPm4Wu4zTI","outputId":"13b195f1-8195-45c0-c0a3-3941c1fe627a"},"outputs":[{"output_type":"stream","name":"stdout","text":["687\n"]}],"source":["# Tokenize the text data\n","tokenizer = Tokenizer()\n","tokenizer.fit_on_texts(text_data)\n","total_words = len(tokenizer.word_index) + 1\n","print(total_words)"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1740750841175,"user":{"displayName":"Priya Pandey","userId":"09641204841115482474"},"user_tz":-330},"id":"7EsgCed35OZO"},"outputs":[],"source":["# Create input sequences\n","input_sequences = []\n","for line in text_data:\n","    token_list = tokenizer.texts_to_sequences([line])[0]\n","    for i in range(1, len(token_list)):\n","        n_gram_sequence = token_list[:i+1]\n","        input_sequences.append(n_gram_sequence)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1740742924752,"user":{"displayName":"Priya Pandey","userId":"09641204841115482474"},"user_tz":-330},"id":"3dmBoCmA6L89","outputId":"8ee104e3-133d-4cd5-a9a2-09001eca2d9b"},"outputs":[{"output_type":"stream","name":"stdout","text":["40\n"]}],"source":["#maximum length of input sequence\n","max_sequence_len = max([len(seq) for seq in input_sequences])\n","print(max_sequence_len)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18,"status":"ok","timestamp":1740742926641,"user":{"displayName":"Priya Pandey","userId":"09641204841115482474"},"user_tz":-330},"id":"LMfUnpjV1gRe","outputId":"46c99777-aed2-4f8b-9892-41396c6a5528"},"outputs":[{"output_type":"stream","name":"stdout","text":["(1628, 39)\n","(1628,)\n","(1628, 687)\n","[[0. 1. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 1. ... 0. 0. 0.]\n"," ...\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 1.]]\n"]}],"source":["\n","# Pad sequences and split into predictors and labels\n","input_sequences = np.array(pad_sequences( input_sequences, maxlen=max_sequence_len, padding='pre'))\n","x = input_sequences[:, :-1]\n","print(x.shape)\n","\n","y=input_sequences[:, -1]\n","print(y.shape)\n","# Convert target data to one-hot encoding\n","y = to_categorical(y, num_classes=total_words)\n","print(y.shape)\n","print(y)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1JcPWi_-7Nhq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1740742931371,"user_tz":-330,"elapsed":19,"user":{"displayName":"Priya Pandey","userId":"09641204841115482474"}},"outputId":"5145b3e9-37f9-4eb3-ee48-9b3c5d316f95"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n","  warnings.warn(\n"]}],"source":["\n","# Define the model\n","model = Sequential()\n","model.add(Embedding(total_words, 10, input_length=max_sequence_len-1))\n","\n","# LSTM layer with Dropout\n","model.add(LSTM(130, return_sequences=True))  # Return sequences for better feature learning\n","model.add(Dropout(0.2))  # 20% Dropout to prevent overfitting\n","model.add(LSTM(100))  # Second LSTM layer for deeper learning\n","\n","# Output layer\n","model.add(Dense(total_words, activation='softmax'))\n","\n","# Compile the model\n","model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","# EarlyStopping with higher patience\n","early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n","\n"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1740750988988,"user":{"displayName":"Priya Pandey","userId":"09641204841115482474"},"user_tz":-330},"id":"FfCv_1DRWnVX"},"outputs":[],"source":["# Train the model\n","model.fit(x, y, epochs=500, verbose=1)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QdUJMW1wihbV"},"outputs":[],"source":["\n","model = load_model(\"/content/drive/MyDrive/Colab Notebooks/next_word_model.keras\")  # Load the saved model\n"]},{"cell_type":"code","source":["from tensorflow.keras.preprocessing.text import Tokenizer\n","import pickle\n","\n","# Load training data from the file\n","file_path = \"/content/drive/MyDrive/pizza.txt\"\n","\n","with open(file_path, \"r\", encoding=\"utf-8\") as file:\n","    training_texts = file.readlines()  # Read all lines into a list\n","\n","training_texts = [line.strip() for line in training_texts]  # Remove extra spaces\n","\n","# Recreate tokenizer\n","tokenizer = Tokenizer()\n","tokenizer.fit_on_texts(training_texts)\n","\n","# Save tokenizer to Google Drive\n","with open('/content/drive/MyDrive/Colab Notebooks/tokenizer.pkl', 'wb') as file:\n","    pickle.dump(tokenizer, file)\n","\n","print(\"Tokenizer saved successfully!\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"At4bmwNLMn-z","executionInfo":{"status":"ok","timestamp":1740742949423,"user_tz":-330,"elapsed":284,"user":{"displayName":"Priya Pandey","userId":"09641204841115482474"}},"outputId":"cdef4d14-0d08-4bbe-e2f2-de9d4c66f502"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Tokenizer saved successfully!\n"]}]},{"cell_type":"code","source":["\n","def predict_next_words(model, tokenizer, input_text, num_words=5, max_sequence_length=max_sequence_len):\n","    for _ in range(num_words):\n","        # Convert input text to a sequence\n","        sequence = tokenizer.texts_to_sequences([input_text])\n","\n","        # Pad the sequence to match the model's expected input size\n","        padded_sequence = pad_sequences(sequence, maxlen=max_sequence_length-1, padding='pre')\n","\n","        # Predict the next word\n","        predicted_probs = model.predict(padded_sequence, verbose=0)\n","\n","        # Get the index of the word with the highest probability\n","        predicted_index = np.argmax(predicted_probs, axis=-1)[0]\n","\n","        # Convert index to word\n","        word_map = {index: word for word, index in tokenizer.word_index.items()}\n","        predicted_word = word_map.get(predicted_index, \"<UNK>\")  # Handle unknown words\n","\n","        # Append the predicted word to the input text\n","        input_text += \" \" + predicted_word\n","\n","    return input_text\n"],"metadata":{"id":"ECSMc1VFKCdc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["input_text = \"Pizza\"\n","predicted_sentence = predict_next_words(model, tokenizer, input_text, num_words=15, max_sequence_length=max_sequence_len)\n","print(\"Generated Sentence:\", predicted_sentence)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VFsvjEx6MI-C","executionInfo":{"status":"ok","timestamp":1740742958086,"user_tz":-330,"elapsed":1873,"user":{"displayName":"Priya Pandey","userId":"09641204841115482474"}},"outputId":"0baaf396-b5c4-4faa-f5b9-b2e60b75bb64"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Generated Sentence: Pizza has become a symbol of comfort happiness and celebration and its iconic triangular slices have\n"]}]},{"cell_type":"code","source":["input_text = \"Technology\"\n","predicted_sentence = predict_next_words(model, tokenizer, input_text, num_words=15, max_sequence_length=max_sequence_len)\n","print(\"Generated Sentence:\", predicted_sentence)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bmxp4vCFPNn_","executionInfo":{"status":"ok","timestamp":1740742964529,"user_tz":-330,"elapsed":3743,"user":{"displayName":"Priya Pandey","userId":"09641204841115482474"}},"outputId":"1cadd49a-8645-4209-c3e3-2f8259f0c8f9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Generated Sentence: Technology will play a significant role in shaping the future of pizza making lies and delivery\n"]}]},{"cell_type":"code","source":["input_text = \"India\"\n","predicted_sentence = predict_next_words(model, tokenizer, input_text, num_words=30, max_sequence_length=max_sequence_len)\n","print(\"Generated Sentence:\", predicted_sentence)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KAndy6-HXcWZ","executionInfo":{"status":"ok","timestamp":1740743086556,"user_tz":-330,"elapsed":2766,"user":{"displayName":"Priya Pandey","userId":"09641204841115482474"}},"outputId":"2e7ca0de-53f2-4ef9-d7fe-805d6a293eca"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Generated Sentence: India is much more than a delicious dish—it is a culinary phenomenon that has captured the hearts and palates of people around the world of process of the beloved fluffy crust\n"]}]}],"metadata":{"colab":{"provenance":[],"mount_file_id":"1KNCDs2Mgz4ULbm_HkFD565nXKclDY6yW","authorship_tag":"ABX9TyNItMT1gQ+yghtQykclZ9PC"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}